{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing necessary libraries ##\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LassoLarsCV, RidgeCV, ElasticNetCV, BayesianRidge, ARDRegression, SGDRegressor, LogisticRegressionCV\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_auto.csv')\n",
    "test = pd.read_csv('test_auto.csv')\n",
    "test_Y = pd.read_csv('SHELL_AUTO.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train['TARGET_FLAG']\n",
    "train_y1 = train['TARGET_AMT']\n",
    "test_y = test_Y['p_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns = ['TARGET_FLAG','TARGET_AMT'])\n",
    "test = test.drop(columns=['TARGET_FLAG','TARGET_AMT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6008\n",
       "1    2153\n",
       "Name: TARGET_FLAG, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      8161.000000\n",
       "mean       1504.324648\n",
       "std        4704.026930\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%        1036.000000\n",
       "max      107586.136160\n",
       "Name: TARGET_AMT, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(actual, predicted):\n",
    "    return np.sqrt(np.sum(np.square(actual-predicted))/len(actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_col = ['AGE', 'YOJ', 'CAR_AGE', 'INCOME', 'HOME_VAL', 'BLUEBOOK', 'OLDCLAIM']\n",
    "\n",
    "for i in val_col:\n",
    "    train[i]=train[i].fillna(0).values\n",
    "    train[i] = train[i].replace('[\\$,]', '', regex=True).astype(float)\n",
    "    \n",
    "train['JOB'] = train['JOB'].fillna('Null').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_col = ['AGE', 'YOJ', 'CAR_AGE', 'INCOME', 'HOME_VAL', 'BLUEBOOK', 'OLDCLAIM']\n",
    "\n",
    "for i in val_col:\n",
    "    test[i] = test[i].fillna(0).values\n",
    "    test[i] = test[i].replace('[\\$,]', '', regex=True).astype(float)\n",
    "    \n",
    "test['JOB'] = test['JOB'].fillna('Null').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARENT1\n",
      "MSTATUS\n",
      "SEX\n",
      "EDUCATION\n",
      "JOB\n",
      "CAR_USE\n",
      "CAR_TYPE\n",
      "RED_CAR\n",
      "REVOKED\n",
      "URBANICITY\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "for column_name in test.columns:\n",
    "    if test[column_name].dtype == object:\n",
    "        print(column_name)\n",
    "        test[column_name] = le.fit_transform(test[column_name].values)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARENT1\n",
      "MSTATUS\n",
      "SEX\n",
      "EDUCATION\n",
      "JOB\n",
      "CAR_USE\n",
      "CAR_TYPE\n",
      "RED_CAR\n",
      "REVOKED\n",
      "URBANICITY\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "for column_name in train.columns:\n",
    "    if train[column_name].dtype == object:\n",
    "        print(column_name)\n",
    "        train[column_name] = le.fit_transform(train[column_name].values)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INDEX           int64\n",
       "KIDSDRIV        int64\n",
       "AGE           float64\n",
       "HOMEKIDS        int64\n",
       "YOJ           float64\n",
       "INCOME        float64\n",
       "PARENT1         int64\n",
       "HOME_VAL      float64\n",
       "MSTATUS         int64\n",
       "SEX             int64\n",
       "EDUCATION       int64\n",
       "JOB             int64\n",
       "TRAVTIME        int64\n",
       "CAR_USE         int64\n",
       "BLUEBOOK      float64\n",
       "TIF             int64\n",
       "CAR_TYPE        int64\n",
       "RED_CAR         int64\n",
       "OLDCLAIM      float64\n",
       "CLM_FREQ        int64\n",
       "REVOKED         int64\n",
       "MVR_PTS         int64\n",
       "CAR_AGE       float64\n",
       "URBANICITY      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm.fit(train,train_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred = lm.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1608.9585813111332"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error(test_y, Ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame()\n",
    "pred['INDEX'] = test['INDEX']\n",
    "pred['TARGET_AMT'] = pd.Series(Ypred)\n",
    "pred = pred.set_index('INDEX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If the amount is greater than 0, then Flag is 1\n",
    "pred.loc[pred['TARGET_AMT'] > 0, 'TARGET_FLAG'] = 1\n",
    "pred.loc[pred['TARGET_AMT'] <= 0, 'TARGET_FLAG'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.to_csv('linear_reg.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgbr = xgb.XGBRegressor(verbosity=0) \n",
    "xgbr.fit(train,train_y1)\n",
    "Ypred = xgbr.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2631.4780231742657"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error(test_y, Ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame()\n",
    "pred['INDEX'] = test['INDEX']\n",
    "pred['TARGET_AMT'] = pd.Series(Ypred)\n",
    "pred = pred.set_index('INDEX')\n",
    "\n",
    "pred.loc[pred['TARGET_AMT'] > 0, 'TARGET_FLAG'] = 1\n",
    "pred.loc[pred['TARGET_AMT'] <= 0, 'TARGET_FLAG'] = 0\n",
    "\n",
    "pred.to_csv('xbg_reg.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(n_estimators=3000, random_state=42)\n",
    "forest.fit(train,train_y1)\n",
    "Ypred = forest.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2332.36389561242"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error(test_y, Ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame()\n",
    "pred['INDEX'] = test['INDEX']\n",
    "pred['TARGET_AMT'] = pd.Series(Ypred)\n",
    "pred = pred.set_index('INDEX')\n",
    "\n",
    "pred.loc[pred['TARGET_AMT'] > 0, 'TARGET_FLAG'] = 1\n",
    "pred.loc[pred['TARGET_AMT'] <= 0, 'TARGET_FLAG'] = 0\n",
    "\n",
    "pred.to_csv('rf_reg.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR : 1608.9585813111332\n",
      "LASSO : 1606.2270391145114\n",
      "MLP : 1092.3373328436373\n",
      "KNN : 2357.738858609399\n",
      "DecisionTree : 5279.924960568266\n",
      "SVR : 345.0493816758177\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "models = []\n",
    "models.append(('LR', LinearRegression()))\n",
    "models.append(('LASSO', Lasso()))\n",
    "models.append(('MLP', MLPRegressor(max_iter = 500)))\n",
    "models.append(('KNN', KNeighborsRegressor()))\n",
    "models.append(('DecisionTree', DecisionTreeRegressor()))\n",
    "models.append(('SVR', SVR()))\n",
    "for name, model in models:\n",
    "    model.fit(train, train_y1)\n",
    "    y = model.predict(test)\n",
    "    print(name + \" : \" + str(mean_squared_error(test_y, y,squared=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 200       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 809\n",
      "Trainable params: 809\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=24, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "164/164 [==============================] - 0s 811us/step - loss: 23531354.0000 - mse: 23531354.0000 - mae: 2235.2588\n",
      "Epoch 2/150\n",
      "164/164 [==============================] - 0s 604us/step - loss: 22286842.0000 - mse: 22286842.0000 - mae: 2138.1382\n",
      "Epoch 3/150\n",
      "164/164 [==============================] - 0s 717us/step - loss: 22283138.0000 - mse: 22283138.0000 - mae: 2128.3083\n",
      "Epoch 4/150\n",
      "164/164 [==============================] - 0s 606us/step - loss: 22396252.0000 - mse: 22396252.0000 - mae: 2142.9858\n",
      "Epoch 5/150\n",
      "164/164 [==============================] - 0s 598us/step - loss: 22274674.0000 - mse: 22274674.0000 - mae: 2129.4114\n",
      "Epoch 6/150\n",
      "164/164 [==============================] - 0s 695us/step - loss: 22254248.0000 - mse: 22254248.0000 - mae: 2113.4216\n",
      "Epoch 7/150\n",
      "164/164 [==============================] - 0s 596us/step - loss: 22157934.0000 - mse: 22157934.0000 - mae: 2115.2524\n",
      "Epoch 8/150\n",
      "164/164 [==============================] - 0s 606us/step - loss: 22178842.0000 - mse: 22178842.0000 - mae: 2117.9456\n",
      "Epoch 9/150\n",
      "164/164 [==============================] - 0s 588us/step - loss: 22290886.0000 - mse: 22290886.0000 - mae: 2149.8267\n",
      "Epoch 10/150\n",
      "164/164 [==============================] - 0s 586us/step - loss: 22113106.0000 - mse: 22113106.0000 - mae: 2112.1465\n",
      "Epoch 11/150\n",
      "164/164 [==============================] - 0s 596us/step - loss: 22107004.0000 - mse: 22107004.0000 - mae: 2118.9739\n",
      "Epoch 12/150\n",
      "164/164 [==============================] - 0s 591us/step - loss: 22062202.0000 - mse: 22062202.0000 - mae: 2100.8533\n",
      "Epoch 13/150\n",
      "164/164 [==============================] - 0s 601us/step - loss: 22112498.0000 - mse: 22112498.0000 - mae: 2114.4045\n",
      "Epoch 14/150\n",
      "164/164 [==============================] - 0s 598us/step - loss: 22086524.0000 - mse: 22086524.0000 - mae: 2119.9258\n",
      "Epoch 15/150\n",
      "164/164 [==============================] - 0s 587us/step - loss: 22041960.0000 - mse: 22041960.0000 - mae: 2090.9783\n",
      "Epoch 16/150\n",
      "164/164 [==============================] - 0s 590us/step - loss: 22116752.0000 - mse: 22116752.0000 - mae: 2135.1965\n",
      "Epoch 17/150\n",
      "164/164 [==============================] - 0s 603us/step - loss: 22031186.0000 - mse: 22031186.0000 - mae: 2100.9858\n",
      "Epoch 18/150\n",
      "164/164 [==============================] - 0s 594us/step - loss: 22101818.0000 - mse: 22101818.0000 - mae: 2101.4790\n",
      "Epoch 19/150\n",
      "164/164 [==============================] - 0s 592us/step - loss: 22093258.0000 - mse: 22093258.0000 - mae: 2127.4412\n",
      "Epoch 20/150\n",
      "164/164 [==============================] - 0s 599us/step - loss: 22028636.0000 - mse: 22028636.0000 - mae: 2104.2280\n",
      "Epoch 21/150\n",
      "164/164 [==============================] - 0s 590us/step - loss: 22005492.0000 - mse: 22005492.0000 - mae: 2101.2502\n",
      "Epoch 22/150\n",
      "164/164 [==============================] - 0s 591us/step - loss: 22016146.0000 - mse: 22016146.0000 - mae: 2105.7986\n",
      "Epoch 23/150\n",
      "164/164 [==============================] - 0s 590us/step - loss: 22094486.0000 - mse: 22094486.0000 - mae: 2117.9299\n",
      "Epoch 24/150\n",
      "164/164 [==============================] - 0s 596us/step - loss: 21994298.0000 - mse: 21994298.0000 - mae: 2098.6758\n",
      "Epoch 25/150\n",
      "164/164 [==============================] - 0s 623us/step - loss: 21981702.0000 - mse: 21981702.0000 - mae: 2093.3955\n",
      "Epoch 26/150\n",
      "164/164 [==============================] - 0s 595us/step - loss: 21973564.0000 - mse: 21973564.0000 - mae: 2081.8948\n",
      "Epoch 27/150\n",
      "164/164 [==============================] - 0s 599us/step - loss: 21957292.0000 - mse: 21957292.0000 - mae: 2104.6145\n",
      "Epoch 28/150\n",
      "164/164 [==============================] - 0s 585us/step - loss: 21985944.0000 - mse: 21985944.0000 - mae: 2099.0642\n",
      "Epoch 29/150\n",
      "164/164 [==============================] - 0s 591us/step - loss: 21972890.0000 - mse: 21972890.0000 - mae: 2110.9014\n",
      "Epoch 30/150\n",
      "164/164 [==============================] - 0s 591us/step - loss: 21991140.0000 - mse: 21991140.0000 - mae: 2079.8042\n",
      "Epoch 31/150\n",
      "164/164 [==============================] - 0s 605us/step - loss: 21962414.0000 - mse: 21962414.0000 - mae: 2103.7747\n",
      "Epoch 32/150\n",
      "164/164 [==============================] - 0s 591us/step - loss: 21950392.0000 - mse: 21950392.0000 - mae: 2091.7134\n",
      "Epoch 33/150\n",
      "164/164 [==============================] - 0s 619us/step - loss: 21916908.0000 - mse: 21916908.0000 - mae: 2093.6589\n",
      "Epoch 34/150\n",
      "164/164 [==============================] - 0s 752us/step - loss: 21903940.0000 - mse: 21903940.0000 - mae: 2086.7102\n",
      "Epoch 35/150\n",
      "164/164 [==============================] - 0s 725us/step - loss: 21965920.0000 - mse: 21965920.0000 - mae: 2086.3540\n",
      "Epoch 36/150\n",
      "164/164 [==============================] - 0s 637us/step - loss: 21896996.0000 - mse: 21896996.0000 - mae: 2084.6062\n",
      "Epoch 37/150\n",
      "164/164 [==============================] - 0s 595us/step - loss: 21942720.0000 - mse: 21942720.0000 - mae: 2091.5330\n",
      "Epoch 38/150\n",
      "164/164 [==============================] - 0s 611us/step - loss: 21942600.0000 - mse: 21942600.0000 - mae: 2089.0825\n",
      "Epoch 39/150\n",
      "164/164 [==============================] - 0s 622us/step - loss: 21880024.0000 - mse: 21880024.0000 - mae: 2080.9421\n",
      "Epoch 40/150\n",
      "164/164 [==============================] - 0s 606us/step - loss: 21937206.0000 - mse: 21937206.0000 - mae: 2084.5698\n",
      "Epoch 41/150\n",
      "164/164 [==============================] - 0s 590us/step - loss: 21878972.0000 - mse: 21878972.0000 - mae: 2096.1384\n",
      "Epoch 42/150\n",
      "164/164 [==============================] - 0s 591us/step - loss: 21904104.0000 - mse: 21904104.0000 - mae: 2091.6987\n",
      "Epoch 43/150\n",
      "164/164 [==============================] - 0s 620us/step - loss: 21902810.0000 - mse: 21902810.0000 - mae: 2068.5979\n",
      "Epoch 44/150\n",
      "164/164 [==============================] - 0s 592us/step - loss: 21909374.0000 - mse: 21909374.0000 - mae: 2092.9810\n",
      "Epoch 45/150\n",
      "164/164 [==============================] - 0s 612us/step - loss: 21878928.0000 - mse: 21878928.0000 - mae: 2085.7468\n",
      "Epoch 46/150\n",
      "164/164 [==============================] - 0s 580us/step - loss: 21875840.0000 - mse: 21875840.0000 - mae: 2084.7141\n",
      "Epoch 47/150\n",
      "164/164 [==============================] - 0s 612us/step - loss: 21922914.0000 - mse: 21922914.0000 - mae: 2075.8108\n",
      "Epoch 48/150\n",
      "164/164 [==============================] - 0s 596us/step - loss: 21909318.0000 - mse: 21909316.0000 - mae: 2085.4214\n",
      "Epoch 49/150\n",
      "164/164 [==============================] - 0s 593us/step - loss: 21860088.0000 - mse: 21860088.0000 - mae: 2074.5227\n",
      "Epoch 50/150\n",
      "164/164 [==============================] - 0s 593us/step - loss: 21900086.0000 - mse: 21900086.0000 - mae: 2087.4558\n",
      "Epoch 51/150\n",
      "164/164 [==============================] - 0s 610us/step - loss: 21908360.0000 - mse: 21908360.0000 - mae: 2109.2651\n",
      "Epoch 52/150\n",
      "164/164 [==============================] - 0s 600us/step - loss: 21836926.0000 - mse: 21836926.0000 - mae: 2068.0571\n",
      "Epoch 53/150\n",
      "164/164 [==============================] - 0s 641us/step - loss: 21812684.0000 - mse: 21812684.0000 - mae: 2076.3276\n",
      "Epoch 54/150\n",
      "164/164 [==============================] - 0s 595us/step - loss: 21833510.0000 - mse: 21833510.0000 - mae: 2087.2214\n",
      "Epoch 55/150\n",
      "164/164 [==============================] - 0s 588us/step - loss: 21841892.0000 - mse: 21841892.0000 - mae: 2072.1184\n",
      "Epoch 56/150\n",
      "164/164 [==============================] - 0s 572us/step - loss: 21872720.0000 - mse: 21872720.0000 - mae: 2094.2349\n",
      "Epoch 57/150\n",
      "164/164 [==============================] - 0s 593us/step - loss: 21839694.0000 - mse: 21839694.0000 - mae: 2067.3162\n",
      "Epoch 58/150\n",
      "164/164 [==============================] - 0s 628us/step - loss: 21852222.0000 - mse: 21852222.0000 - mae: 2092.4937\n",
      "Epoch 59/150\n",
      "164/164 [==============================] - 0s 591us/step - loss: 21830030.0000 - mse: 21830030.0000 - mae: 2080.7642\n",
      "Epoch 60/150\n",
      "164/164 [==============================] - 0s 629us/step - loss: 21790830.0000 - mse: 21790830.0000 - mae: 2078.9116\n",
      "Epoch 61/150\n",
      "164/164 [==============================] - 0s 581us/step - loss: 21825580.0000 - mse: 21825580.0000 - mae: 2079.3381\n",
      "Epoch 62/150\n",
      "164/164 [==============================] - 0s 585us/step - loss: 21816634.0000 - mse: 21816634.0000 - mae: 2080.1362\n",
      "Epoch 63/150\n",
      "164/164 [==============================] - 0s 589us/step - loss: 21831326.0000 - mse: 21831324.0000 - mae: 2081.0222\n",
      "Epoch 64/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 0s 592us/step - loss: 21804214.0000 - mse: 21804214.0000 - mae: 2083.9131\n",
      "Epoch 65/150\n",
      "164/164 [==============================] - 0s 564us/step - loss: 21766906.0000 - mse: 21766906.0000 - mae: 2065.4058\n",
      "Epoch 66/150\n",
      "164/164 [==============================] - 0s 574us/step - loss: 21837896.0000 - mse: 21837896.0000 - mae: 2084.1868\n",
      "Epoch 67/150\n",
      "164/164 [==============================] - 0s 579us/step - loss: 21825472.0000 - mse: 21825472.0000 - mae: 2083.6331\n",
      "Epoch 68/150\n",
      "164/164 [==============================] - 0s 576us/step - loss: 21754544.0000 - mse: 21754544.0000 - mae: 2063.1223\n",
      "Epoch 69/150\n",
      "164/164 [==============================] - 0s 568us/step - loss: 21798858.0000 - mse: 21798858.0000 - mae: 2104.2224\n",
      "Epoch 70/150\n",
      "164/164 [==============================] - 0s 576us/step - loss: 21793876.0000 - mse: 21793876.0000 - mae: 2064.4722\n",
      "Epoch 71/150\n",
      "164/164 [==============================] - 0s 618us/step - loss: 21786582.0000 - mse: 21786582.0000 - mae: 2076.4478\n",
      "Epoch 72/150\n",
      "164/164 [==============================] - 0s 567us/step - loss: 21793212.0000 - mse: 21793212.0000 - mae: 2072.4990\n",
      "Epoch 73/150\n",
      "164/164 [==============================] - 0s 565us/step - loss: 21779718.0000 - mse: 21779718.0000 - mae: 2083.2876\n",
      "Epoch 74/150\n",
      "164/164 [==============================] - 0s 605us/step - loss: 21767594.0000 - mse: 21767594.0000 - mae: 2077.9194\n",
      "Epoch 75/150\n",
      "164/164 [==============================] - 0s 612us/step - loss: 21777260.0000 - mse: 21777260.0000 - mae: 2086.9685\n",
      "Epoch 76/150\n",
      "164/164 [==============================] - 0s 567us/step - loss: 21771266.0000 - mse: 21771266.0000 - mae: 2079.8728\n",
      "Epoch 77/150\n",
      "164/164 [==============================] - 0s 580us/step - loss: 21745566.0000 - mse: 21745566.0000 - mae: 2089.3127\n",
      "Epoch 78/150\n",
      "164/164 [==============================] - 0s 582us/step - loss: 21760704.0000 - mse: 21760704.0000 - mae: 2072.7402\n",
      "Epoch 79/150\n",
      "164/164 [==============================] - 0s 572us/step - loss: 21754666.0000 - mse: 21754666.0000 - mae: 2073.3958\n",
      "Epoch 80/150\n",
      "164/164 [==============================] - 0s 568us/step - loss: 21772088.0000 - mse: 21772088.0000 - mae: 2093.3376\n",
      "Epoch 81/150\n",
      "164/164 [==============================] - 0s 566us/step - loss: 21779128.0000 - mse: 21779128.0000 - mae: 2075.0620\n",
      "Epoch 82/150\n",
      "164/164 [==============================] - 0s 576us/step - loss: 21760970.0000 - mse: 21760970.0000 - mae: 2076.5156\n",
      "Epoch 83/150\n",
      "164/164 [==============================] - 0s 587us/step - loss: 21704118.0000 - mse: 21704118.0000 - mae: 2085.7217\n",
      "Epoch 84/150\n",
      "164/164 [==============================] - 0s 577us/step - loss: 21732398.0000 - mse: 21732398.0000 - mae: 2074.0381\n",
      "Epoch 85/150\n",
      "164/164 [==============================] - 0s 571us/step - loss: 21742028.0000 - mse: 21742028.0000 - mae: 2079.1709\n",
      "Epoch 86/150\n",
      "164/164 [==============================] - 0s 568us/step - loss: 21731610.0000 - mse: 21731610.0000 - mae: 2083.9653\n",
      "Epoch 87/150\n",
      "164/164 [==============================] - 0s 569us/step - loss: 21749820.0000 - mse: 21749820.0000 - mae: 2087.4871\n",
      "Epoch 88/150\n",
      "164/164 [==============================] - 0s 580us/step - loss: 21689800.0000 - mse: 21689800.0000 - mae: 2077.0176\n",
      "Epoch 89/150\n",
      "164/164 [==============================] - 0s 580us/step - loss: 21777394.0000 - mse: 21777394.0000 - mae: 2108.2913\n",
      "Epoch 90/150\n",
      "164/164 [==============================] - 0s 582us/step - loss: 21772226.0000 - mse: 21772226.0000 - mae: 2093.5112\n",
      "Epoch 91/150\n",
      "164/164 [==============================] - 0s 569us/step - loss: 21767238.0000 - mse: 21767238.0000 - mae: 2067.4009\n",
      "Epoch 92/150\n",
      "164/164 [==============================] - 0s 565us/step - loss: 21714256.0000 - mse: 21714256.0000 - mae: 2072.5510\n",
      "Epoch 93/150\n",
      "164/164 [==============================] - 0s 579us/step - loss: 21731500.0000 - mse: 21731500.0000 - mae: 2098.0830\n",
      "Epoch 94/150\n",
      "164/164 [==============================] - 0s 672us/step - loss: 21694348.0000 - mse: 21694348.0000 - mae: 2074.7722\n",
      "Epoch 95/150\n",
      "164/164 [==============================] - 0s 594us/step - loss: 21741696.0000 - mse: 21741696.0000 - mae: 2092.7917\n",
      "Epoch 96/150\n",
      "164/164 [==============================] - 0s 565us/step - loss: 21754640.0000 - mse: 21754640.0000 - mae: 2080.9421\n",
      "Epoch 97/150\n",
      "164/164 [==============================] - 0s 572us/step - loss: 21716904.0000 - mse: 21716904.0000 - mae: 2071.0178\n",
      "Epoch 98/150\n",
      "164/164 [==============================] - 0s 573us/step - loss: 21710244.0000 - mse: 21710244.0000 - mae: 2097.5813\n",
      "Epoch 99/150\n",
      "164/164 [==============================] - 0s 581us/step - loss: 21690118.0000 - mse: 21690118.0000 - mae: 2069.1553\n",
      "Epoch 100/150\n",
      "164/164 [==============================] - 0s 587us/step - loss: 21742622.0000 - mse: 21742622.0000 - mae: 2073.0791\n",
      "Epoch 101/150\n",
      "164/164 [==============================] - 0s 572us/step - loss: 21755456.0000 - mse: 21755456.0000 - mae: 2093.2705\n",
      "Epoch 102/150\n",
      "164/164 [==============================] - 0s 574us/step - loss: 21687754.0000 - mse: 21687754.0000 - mae: 2084.7891\n",
      "Epoch 103/150\n",
      "164/164 [==============================] - 0s 588us/step - loss: 21711276.0000 - mse: 21711276.0000 - mae: 2084.6145\n",
      "Epoch 104/150\n",
      "164/164 [==============================] - 0s 604us/step - loss: 21746692.0000 - mse: 21746692.0000 - mae: 2081.1174\n",
      "Epoch 105/150\n",
      "164/164 [==============================] - 0s 576us/step - loss: 21726062.0000 - mse: 21726062.0000 - mae: 2079.0994\n",
      "Epoch 106/150\n",
      "164/164 [==============================] - 0s 566us/step - loss: 21698682.0000 - mse: 21698682.0000 - mae: 2088.5369\n",
      "Epoch 107/150\n",
      "164/164 [==============================] - 0s 584us/step - loss: 21700144.0000 - mse: 21700144.0000 - mae: 2065.1101\n",
      "Epoch 108/150\n",
      "164/164 [==============================] - 0s 576us/step - loss: 21692192.0000 - mse: 21692192.0000 - mae: 2081.1929\n",
      "Epoch 109/150\n",
      "164/164 [==============================] - 0s 584us/step - loss: 21686610.0000 - mse: 21686610.0000 - mae: 2069.1304\n",
      "Epoch 110/150\n",
      "164/164 [==============================] - 0s 572us/step - loss: 21707404.0000 - mse: 21707404.0000 - mae: 2094.1372\n",
      "Epoch 111/150\n",
      "164/164 [==============================] - 0s 583us/step - loss: 21709940.0000 - mse: 21709940.0000 - mae: 2084.5093\n",
      "Epoch 112/150\n",
      "164/164 [==============================] - 0s 580us/step - loss: 21739640.0000 - mse: 21739640.0000 - mae: 2070.1641\n",
      "Epoch 113/150\n",
      "164/164 [==============================] - 0s 572us/step - loss: 21708626.0000 - mse: 21708626.0000 - mae: 2100.1421\n",
      "Epoch 114/150\n",
      "164/164 [==============================] - 0s 600us/step - loss: 21655462.0000 - mse: 21655462.0000 - mae: 2060.8313\n",
      "Epoch 115/150\n",
      "164/164 [==============================] - 0s 588us/step - loss: 21712390.0000 - mse: 21712390.0000 - mae: 2091.6494\n",
      "Epoch 116/150\n",
      "164/164 [==============================] - 0s 637us/step - loss: 21685452.0000 - mse: 21685452.0000 - mae: 2070.5566\n",
      "Epoch 117/150\n",
      "164/164 [==============================] - 0s 590us/step - loss: 21691142.0000 - mse: 21691142.0000 - mae: 2096.8940\n",
      "Epoch 118/150\n",
      "164/164 [==============================] - 0s 597us/step - loss: 21664094.0000 - mse: 21664094.0000 - mae: 2080.2107\n",
      "Epoch 119/150\n",
      "164/164 [==============================] - 0s 586us/step - loss: 21702714.0000 - mse: 21702712.0000 - mae: 2071.7996\n",
      "Epoch 120/150\n",
      "164/164 [==============================] - 0s 593us/step - loss: 21728098.0000 - mse: 21728098.0000 - mae: 2086.5186\n",
      "Epoch 121/150\n",
      "164/164 [==============================] - 0s 707us/step - loss: 21708896.0000 - mse: 21708896.0000 - mae: 2089.8628\n",
      "Epoch 122/150\n",
      "164/164 [==============================] - 0s 614us/step - loss: 21656828.0000 - mse: 21656828.0000 - mae: 2077.3875\n",
      "Epoch 123/150\n",
      "164/164 [==============================] - 0s 633us/step - loss: 21648428.0000 - mse: 21648428.0000 - mae: 2062.9045\n",
      "Epoch 124/150\n",
      "164/164 [==============================] - 0s 609us/step - loss: 21721386.0000 - mse: 21721386.0000 - mae: 2084.1021\n",
      "Epoch 125/150\n",
      "164/164 [==============================] - 0s 607us/step - loss: 21645482.0000 - mse: 21645480.0000 - mae: 2082.9404\n",
      "Epoch 126/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 0s 623us/step - loss: 21653324.0000 - mse: 21653324.0000 - mae: 2074.6580\n",
      "Epoch 127/150\n",
      "164/164 [==============================] - 0s 610us/step - loss: 21730684.0000 - mse: 21730684.0000 - mae: 2079.9165\n",
      "Epoch 128/150\n",
      "164/164 [==============================] - 0s 608us/step - loss: 21650124.0000 - mse: 21650124.0000 - mae: 2070.1997\n",
      "Epoch 129/150\n",
      "164/164 [==============================] - 0s 598us/step - loss: 21668490.0000 - mse: 21668492.0000 - mae: 2086.2222\n",
      "Epoch 130/150\n",
      "164/164 [==============================] - 0s 612us/step - loss: 21639518.0000 - mse: 21639518.0000 - mae: 2069.8679\n",
      "Epoch 131/150\n",
      "164/164 [==============================] - 0s 600us/step - loss: 21658182.0000 - mse: 21658182.0000 - mae: 2087.9399\n",
      "Epoch 132/150\n",
      "164/164 [==============================] - 0s 618us/step - loss: 21648818.0000 - mse: 21648818.0000 - mae: 2081.3435\n",
      "Epoch 133/150\n",
      "164/164 [==============================] - 0s 602us/step - loss: 21633978.0000 - mse: 21633978.0000 - mae: 2078.7932\n",
      "Epoch 134/150\n",
      "164/164 [==============================] - 0s 652us/step - loss: 21670478.0000 - mse: 21670478.0000 - mae: 2069.0388\n",
      "Epoch 135/150\n",
      "164/164 [==============================] - 0s 604us/step - loss: 21623088.0000 - mse: 21623088.0000 - mae: 2084.0383\n",
      "Epoch 136/150\n",
      "164/164 [==============================] - 0s 597us/step - loss: 21619962.0000 - mse: 21619962.0000 - mae: 2069.7917\n",
      "Epoch 137/150\n",
      "164/164 [==============================] - 0s 624us/step - loss: 21620808.0000 - mse: 21620808.0000 - mae: 2073.4556\n",
      "Epoch 138/150\n",
      "164/164 [==============================] - 0s 606us/step - loss: 21605240.0000 - mse: 21605240.0000 - mae: 2089.7065\n",
      "Epoch 139/150\n",
      "164/164 [==============================] - 0s 621us/step - loss: 21670896.0000 - mse: 21670898.0000 - mae: 2096.6946\n",
      "Epoch 140/150\n",
      "164/164 [==============================] - 0s 609us/step - loss: 21728272.0000 - mse: 21728272.0000 - mae: 2078.6592\n",
      "Epoch 141/150\n",
      "164/164 [==============================] - 0s 606us/step - loss: 21645780.0000 - mse: 21645780.0000 - mae: 2094.4053\n",
      "Epoch 142/150\n",
      "164/164 [==============================] - 0s 600us/step - loss: 21607858.0000 - mse: 21607858.0000 - mae: 2068.8413\n",
      "Epoch 143/150\n",
      "164/164 [==============================] - 0s 611us/step - loss: 21616656.0000 - mse: 21616656.0000 - mae: 2076.9180\n",
      "Epoch 144/150\n",
      "164/164 [==============================] - 0s 608us/step - loss: 21612572.0000 - mse: 21612572.0000 - mae: 2080.7815\n",
      "Epoch 145/150\n",
      "164/164 [==============================] - 0s 609us/step - loss: 21597372.0000 - mse: 21597374.0000 - mae: 2075.8257\n",
      "Epoch 146/150\n",
      "164/164 [==============================] - 0s 602us/step - loss: 21635484.0000 - mse: 21635484.0000 - mae: 2078.5691\n",
      "Epoch 147/150\n",
      "164/164 [==============================] - 0s 611us/step - loss: 21611060.0000 - mse: 21611060.0000 - mae: 2076.6392\n",
      "Epoch 148/150\n",
      "164/164 [==============================] - 0s 609us/step - loss: 21617086.0000 - mse: 21617086.0000 - mae: 2070.0459\n",
      "Epoch 149/150\n",
      "164/164 [==============================] - 0s 607us/step - loss: 21618546.0000 - mse: 21618546.0000 - mae: 2085.1824\n",
      "Epoch 150/150\n",
      "164/164 [==============================] - 0s 609us/step - loss: 21623664.0000 - mse: 21623664.0000 - mae: 2086.3870\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, train_y1, epochs=150, batch_size=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mse', 'mae'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2281.582  ],\n",
       "       [2763.805  ],\n",
       "       [ 322.1449 ],\n",
       "       ...,\n",
       "       [ 380.19476],\n",
       "       [3625.948  ],\n",
       "       [ 968.3492 ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector regression and Multi-layer Perceptron regressor performed significantly better than the baseline linear algorithms (linear regression and Lasso). This is possible due to their ability to account for nonlinear interactions between the predictor variables and the severity loss!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
